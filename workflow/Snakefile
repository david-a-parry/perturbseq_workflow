import pandas as pd
from snakemake.utils import validate
from snakemake.remote.HTTP import RemoteProvider as HTTPRemoteProvider

HTTP = HTTPRemoteProvider()

configfile: "config/config.yaml"
print(config)
validate(config, schema="schemas/config.schema.yaml")

samples = (
    pd.read_csv(config["samples"], sep="\t", dtype={"sample_name": str})
    .set_index("sample_name", drop=False)
    .sort_index()
)
validate(samples, schema="schemas/samples.schema.yaml")

units = (
    pd.read_csv(config["units"],
                sep="\t",
                dtype={"sample_name": str, "unit_name": str})
    .set_index(["sample_name", "unit_name"], drop=False)
    .sort_index()
)
validate(units, schema="schemas/units.schema.yaml")

all_output = ["results/plots/bagel_pr_curve.pdf",
              "results/plots/bagel_ess_neg_dist.pdf",
              "results/plots/jacks_pr_curve.pdf",
              "results/plots/jacks_ess_neg_dist.pdf"]
if config.get('control_genotype') is not None:
    all_output.append("results/regression_analyses/regression_hits.xlsx")
t0 = samples.timepoint.min()
timepoints = list(samples[samples.timepoint != t0].timepoint.unique())
genotypes = list(samples.genotype.unique())

local_guides_xlsx = os.path.join(
    "resources",
    os.path.basename(config["guides"]))
fa_prfx, _ = os.path.splitext(os.path.basename(config["guides"]))
guides_fasta = os.path.join("resources", fa_prfx + '.fa')
bt_idx = os.path.join("resources",
                      "bowtie_index",
                      os.path.splitext(os.path.basename(guides_fasta))[0])

def get_bagel_ref_genes():
    ess = config.get("bagel_ess_genes")
    neg = config.get("bagel_neg_genes")
    if ess is None or neg is None:
        species = config.get("species")
        if species is None or species.lower() == 'human':
            ess = ess if ess is not None else "resources/bagel/CEGv2.txt"
            neg = neg if neg is not None else "resources/bagel/NEGv1.txt"
        elif species.lower() == 'mouse':
            ess = ess if ess is not None else "resources/bagel/CEG_mouse.txt"
            neg = neg if neg is not None else "resources/bagel/NEG_mouse.txt"
        else:
            raise ValueError("Unsupported species: {}".format(species))
    return ess, neg


def get_original_fastq(wildcards):
    """Get fastq files of given sample-unit."""
    return units.loc[(wildcards.sample_name, wildcards.unit_name), ["fq1"]].dropna()


def get_trimmed_fastq(wildcards):
    """Get fastq files of given sample-unit."""
    fq = get_original_fastq(wildcards)
    return os.path.join("trimmed_fastq",
                        "{}-{}-trimmed.fastq.gz".format(wildcards.sample_name,
                                                        wildcards.unit_name))


def get_fastq(wildcards):
    """Get fastq files of given sample-unit."""
    if config.get('trim', 0) == 0 and config.get('max_length', 20) >= 20:
        return get_original_fastq(wildcards)
    return get_trimmed_fastq(wildcards)


def all_alignments(wildcards):
    return ["alignments/{}-{}.bam".format(sample, unit) for (sample, unit) in
            units.index]


def all_read_counts(wildcards):
    return ["results/read_counts/per_bam/{}-{}_counts.csv.gz".format(sample,
                                                                     unit)
            for (sample, unit) in units.index]


def get_t0_sample(wildcards):
    smpls = samples[(samples.genotype == wildcards.genotype) &
                    (samples.timepoint == t0)].sample_name.values
    if len(smpls) != 1:
        raise ValueError("Expected exactly 1 T0 sample for genotype " +
                         "{}, got {}".format(wildcards.genotype,
                                             ", ".join(smpls) if smpls else 0))
    return smpls[0]


def get_bagel_samples(wildcards):
    return ','.join(
        samples[(samples.genotype == wildcards.genotype) &
                (samples.timepoint == int(wildcards.timepoint))
                ].sample_name.unique())


bagel_ess_genes, bagel_neg_genes = get_bagel_ref_genes()


rule all:
    input:
        all_output


rule download_guides:
    input:
        HTTP.remote(config["guides"], keep_local=True)
    output:
        local_guides_xlsx
    log:
        "logs/download_guides.log"
    run:
        shell("mv {input} {local_guides_xlsx} 2> {log}")

rule build_reference:
    input:
        local_guides_xlsx
    output:
        guides_fasta
    conda:
        "envs/pandas.yaml"
    log:
        "logs/build_reference.log"
    script:
        "scripts/ref_from_xlsx.py"

rule bt_index_reference:
    input:
        guides_fasta
    params:
        prefix = bt_idx,
    output:
        ebwt1 = bt_idx + '.1.ebwt',
        ebwt2 = bt_idx + '.2.ebwt',
        ebwt3 = bt_idx + '.3.ebwt',
        ebwt4 = bt_idx + '.4.ebwt',
        ebwtrev1 = bt_idx + '.rev.1.ebwt',
        ebwtrev2 = bt_idx + '.rev.2.ebwt'
    log:
        "logs/bt_index_reference.log"
    conda:
        "envs/bowtie.yaml"
    shell:
        "bowtie-build --threads {threads} -f {input} {params.prefix} 2>&1 >{log}"

rule faidx_index_reference:
    input:
        guides_fasta
    output:
        guides_fasta + '.fai'
    log:
        "logs/faidx_index_reference.log"
    conda:
        "envs/bowtie.yaml"
    shell:
        "samtools faidx {input} 2>> {log}"

rule trim_fastq:
    input:
        get_original_fastq
    output:
        "trimmed_fastq/{sample_name}-{unit_name}-trimmed.fastq.gz"
    log:
        "logs/trim_fq/{sample_name}_{unit_name}.log"
    conda:
        "envs/pandas.yaml"
    script:
        "scripts/trim_fq.py"

rule bowtie_map:
    input:
        fq = get_fastq,
        ebwt1 = bt_idx + '.1.ebwt',
        ebwt2 = bt_idx + '.2.ebwt',
        ebwt3 = bt_idx + '.3.ebwt',
        ebwt4 = bt_idx + '.4.ebwt',
        ebwtrev1 = bt_idx + '.rev.1.ebwt',
        ebwtrev2 = bt_idx + '.rev.2.ebwt'
    params:
        ref_idx = bt_idx
    output:
        "alignments/{sample_name}-{unit_name}.bam"
    log:
        "logs/bowtie_map/{sample_name}_{unit_name}.log"
    conda:
        "envs/bowtie.yaml"
    resources:
        tmpdir="tmp"
    threads: 8
    shell:
        "(bowtie -m 1 -v 2 -p {threads} {params.ref_idx} {input.fq} -S | "
        "samtools sort -O BAM "
        "-T tmp/{wildcards.sample_name}_{wildcards.unit_name} - )"
        "> {output} 2> {log} && samtools index {output} 2>> {log}"

rule count_reads:
    input:
        "alignments/{sample_name}-{unit_name}.bam",
        guides_fasta,
        guides_fasta + '.fai'
    output:
        read_counts = "results/read_counts/per_bam/{sample_name}-{unit_name}_counts.csv.gz",
        map_counts = "results/read_counts/per_bam/{sample_name}-{unit_name}_mapped.csv.gz"
    log:
        "logs/read_counts/{sample_name}_{unit_name}.log"
    conda:
        "envs/pandas.yaml"
    script:
        "scripts/read_counts_from_bam.py"

rule combine_read_counts:
    input:
        all_read_counts
    output:
        "results/read_counts/read_counts_per_alignment.csv.gz",
        "results/read_counts/read_counts_per_sample.csv.gz",
        "results/read_counts/all_read_counts.tsv",
        expand("results/read_counts/{genotype}_read_counts.tsv", genotype=genotypes)
    conda:
        "envs/pandas.yaml"
    script:
        "scripts/combine_read_counts.py"

rule plot_guide_counts:
    input:
        "results/read_counts/read_counts_per_sample.csv.gz",
    output:
        "results/plots/lorenz_curves_t0.pdf",
        "results/plots/guide_counts_t0.pdf",
        "results/plots/guide_counts_all.pdf",
        "results/read_counts/norm_counts.tsv.gz",
        "results/read_counts/fold_change.tsv"
    conda:
        "envs/stats.yaml"
    notebook:
        "notebooks/guide_plots.py.ipynb"

rule download_bagel:
    input:
        HTTP.remote(config["bagel_zip"])
    output:
        "resources/bagel/BAGEL.py"
    log:
        "logs/download_bagel.log"
    run:
        shell("unzip -o {config[bagel_zip]} -d resources 2>&1 >{log}")
        shell("mkdir -p resources/bagel 2>> {log}")
        shell("mv resources/bagel-*/* resources/bagel 2>> {log}")
        shell("rmdir resources/bagel-* 2>> {log}")

rule run_bagel_fc:
    input:
        "results/read_counts/{genotype}_read_counts.tsv",
        "resources/bagel/BAGEL.py"
    output:
        "results/bagel/{genotype}.foldchange"
    log:
        "logs/bagel-fc-{genotype}.log"
    conda:
        "envs/stats.yaml"
    params:
        control_sample = get_t0_sample,
        prefix = "results/bagel/{genotype}"
    shell:
        "python resources/bagel/BAGEL.py fc -i {input[0]} -o {params.prefix} "
        "-c {params.control_sample} 2> {log}"


rule run_bagel_bf:
    input:
        "results/bagel/{genotype}.foldchange"
    output:
        "results/bagel/{genotype}-{timepoint}.bf"
    log:
        "logs/bagel-bf-{genotype}-{timepoint}.log"
    conda:
        "envs/stats.yaml"
    params:
        sample_cols = get_bagel_samples,
        neg = bagel_neg_genes,
        ess = bagel_ess_genes
    shell:
        "python resources/bagel/BAGEL.py bf -i {input[0]} -o {output} "
        "-n {params.neg} -e {params.ess} -c {params.sample_cols} 2>&1 >{log}"

rule run_bagel_pr:
    input:
        "results/bagel/{genotype}-{timepoint}.bf"
    output:
        "results/bagel/{genotype}-{timepoint}.pr"
    log:
        "logs/bagel-pr-{genotype}-{timepoint}.log"
    conda:
        "envs/stats.yaml"
    params:
        neg = bagel_neg_genes,
        ess = bagel_ess_genes
    shell:
        "python resources/bagel/BAGEL.py pr -i {input} -o {output} "
        "-n {params.neg} -e {params.ess} 2> {log}"

rule plot_bagel_results:
    input:
        expand("results/bagel/{gt}-{time}.pr", gt=genotypes, time=timepoints)
    output:
        "results/plots/bagel_pr_curve.pdf",
        "results/plots/bagel_ess_neg_dist.pdf"
    conda:
        "envs/stats.yaml"
    log:
        "logs/plot_bagel_results.log"
    params:
        neg = bagel_neg_genes,
        ess = bagel_ess_genes
    notebook:
        "notebooks/plot_bagel_results.py.ipynb"

rule prepare_jacks_maps:
    input:
        "results/read_counts/norm_counts.tsv.gz"
    output:
        replicate_map = "results/jacks_analysis/replicate_map.txt",
        sgrna_map = "results/jacks_analysis/sgrna_map.txt"
    log:
        "logs/prepare_jacks_maps.log"
    conda:
        "envs/pandas.yaml"
    script:
        "scripts/prepare_jacks_maps.py"

rule run_jacks:
    input:
        read_counts = "results/read_counts/all_read_counts.tsv",
        replicate_map = "results/jacks_analysis/replicate_map.txt",
        sgrna_map = "results/jacks_analysis/sgrna_map.txt",
        bagel = "resources/bagel/BAGEL.py"  # run after bagel install in case we need NEG genes
    output:
        "results/jacks_analysis/jacks_gene_JACKS_results.txt"
    conda:
        "envs/jacks.yaml"
    log:
        "logs/run_jacks.log"
    params:
        neg = bagel_neg_genes
    shell:
        "JACKS.py {input.read_counts} "
        "{input.replicate_map} {input.sgrna_map} "
        "--ctrl_sample_hdr=Control --gene_hdr=Gene --sgrna_hdr Target "
        "--outprefix=results/jacks_analysis/jacks "
        "--ctrl_genes={params.neg} 2> {log}"

rule plot_jacks_results:
    input:
        "results/jacks_analysis/jacks_gene_JACKS_results.txt",
    output:
        "results/plots/jacks_pr_curve.pdf",
        "results/plots/jacks_ess_neg_dist.pdf"
    conda:
        "envs/stats.yaml"
    log:
        "logs/plot_jacks_results.log"
    params:
        neg = bagel_neg_genes,
        ess = bagel_ess_genes
    notebook:
        "notebooks/plot_jacks_results.py.ipynb"

rule regression_analysis:
    input:
        "results/jacks_analysis/jacks_gene_JACKS_results.txt",
        expand("results/bagel/{gt}-{time}.pr", gt=genotypes, time=timepoints)
    output:
        "results/regression_analyses/regression_hits.xlsx"
    conda:
        "envs/stats.yaml"
    params:
        neg = bagel_neg_genes,
        ess = bagel_ess_genes
    notebook:
        "notebooks/regression_analysis.py.ipynb"
