{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "sns.set_context(\"talk\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysam\n",
    "\n",
    "nt_pal = sns.xkcd_palette([\"medium green\", \"sky blue\", \"goldenrod\", \"red\",\n",
    "                           \"light purple\"])\n",
    "nt2i = dict((k,n) for n,k in enumerate(\"ACGTN\"))\n",
    "\n",
    "\n",
    "def target_from_ref(seqname):\n",
    "    '''Return the gene, strand and exon from guide fasta sequence name'''\n",
    "    try:\n",
    "        chrom, start, end, gene, strand, x, exon = seqname.split('_')\n",
    "    except ValueError:\n",
    "        #controls\n",
    "        try:\n",
    "            chrom, exon, end, gene, strand, x = seqname.split('_')\n",
    "        except ValueError:\n",
    "            raise RuntimeError(\"Could not parse sequence name: {}\".format(\n",
    "                seqname))\n",
    "    strand = strand.replace('~', '-')\n",
    "    return (gene, strand, exon)\n",
    "\n",
    "\n",
    "def nucleotide_counts_from_fasta(ref_fasta):\n",
    "    ''' Assumes all FASTA records are the same length'''\n",
    "    nt_counts = [] #2-d - 1st dimension is Cycle, 2nd is Nucleotide (A,C,G,T,N)\n",
    "    with open (ref_fasta, 'rt') as fa:\n",
    "        c = 0\n",
    "        for line in fa:\n",
    "            if line.startswith(\">\"):\n",
    "                c = 0\n",
    "                continue\n",
    "            if not nt_counts:\n",
    "                for i,n in enumerate(line.rstrip()):\n",
    "                    nt_counts.append([0] * 5)\n",
    "            for i,n in enumerate(line.rstrip()):\n",
    "                nt_counts[i][nt2i[n]] += 1\n",
    "    ref_fa_nt_counts = defaultdict(list)\n",
    "    for i,row in enumerate(nt_counts):\n",
    "        for j,n in enumerate(\"ACGTN\"):\n",
    "            ref_fa_nt_counts[\"Cycle\"].append(i+1)\n",
    "            ref_fa_nt_counts[\"Nucleotide\"].append(n)\n",
    "            ref_fa_nt_counts[\"Count\"].append(row[j])\n",
    "    return pd.DataFrame.from_dict(ref_fa_nt_counts)\n",
    "\n",
    "\n",
    "def plot_fasta_nucleotide_counts(ref_fasta,\n",
    "                                 title=\"Guide Sequences Nucleotide Counts\",\n",
    "                                 palette=None):\n",
    "    '''\n",
    "        Create a stacked bar plot of nucleotide frequencies from a\n",
    "        reference FASTA file of equal lengthed sequences.\n",
    "\n",
    "        Args:\n",
    "            ref_fasta:  Path to FASTA file\n",
    "\n",
    "            title:      Title for plot. Default = \"Guide Sequences\n",
    "                        Nucleotide Counts\"\n",
    "\n",
    "            palette:    Name of palette to use if the default colorscheme\n",
    "                        is not suitable for your purposes. Must available\n",
    "                        via seaborn's color_palette method (see\n",
    "                        https://seaborn.pydata.org/tutorial/color_palettes.html)\n",
    "\n",
    "    '''\n",
    "    if palette is None:\n",
    "        pal = nt_pal\n",
    "    else:\n",
    "        pal = sns.color_palette(palette, 5)\n",
    "    ref_fa_nt_counts = nucleotide_counts_from_fasta(ref_fasta)\n",
    "    plt.figure(figsize=(12,9))\n",
    "    margin_bottom = np.zeros(len(ref_fa_nt_counts.Cycle.drop_duplicates()))\n",
    "    for nt,i in nt2i.items():\n",
    "        color = pal[i]\n",
    "        tmp_df = ref_fa_nt_counts[(ref_fa_nt_counts.Nucleotide == nt)]\n",
    "        plt.bar(tmp_df.Cycle.values, tmp_df.Count.values, color=color,\n",
    "                edgecolor='white', width=1, label=nt, bottom=margin_bottom)\n",
    "        margin_bottom += tmp_df.Count.values\n",
    "    plt.xlabel(\"Cycle\")\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.title(title)\n",
    "    ylim = plt.ylim()\n",
    "    new_ylim = [ylim[0], ylim[1] * 1.05]\n",
    "    plt.ylim(new_ylim)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cycle_counts_from_fq(fq,\n",
    "                         progress_interval=1000000):\n",
    "    '''\n",
    "        Returns a dataframe of nucleotide counts per cycle for FASTQ in fq_dir.\n",
    "        Assumes all FASTQs end '.fastq.gz'. Specify a different value for\n",
    "        'extension' if your FASTQs do not end with this extension.\n",
    "\n",
    "        Args:\n",
    "            fq_dir:    Directory containing FASTQs to analyze\n",
    "\n",
    "    '''\n",
    "    fq_nt_counts = dict()\n",
    "    with pysam.FastxFile(fq) as fqfile:\n",
    "        nt_counts = []  #2-d - 1st dimension is Cycle, 2nd is NT (A,C,G,T,N)\n",
    "        first = next(fqfile)\n",
    "        for i, n in enumerate(first.sequence):\n",
    "            nt_counts.append([0] * 5)\n",
    "            nt_counts[i][nt2i[n]] += 1\n",
    "        records = 1\n",
    "        for entry in fqfile:\n",
    "            if (progress_interval is not None\n",
    "                    and records % progress_interval == 0):\n",
    "                print(\"Processed {:,} records for {}\".format(\n",
    "                    records, bn))\n",
    "            for i, n in enumerate(\n",
    "                    entry.sequence):  #assume all same length(?)\n",
    "                try:\n",
    "                    nt_counts[i][nt2i[n]] += 1\n",
    "                except IndexError:\n",
    "                    nt_counts.append([0] * 5)\n",
    "                    nt_counts[i][nt2i[n]] += 1\n",
    "            records += 1\n",
    "        print(\"Finished processing {:,} records for {}\".format(\n",
    "              records, fq))\n",
    "        return nt_counts\n",
    "    \n",
    "\n",
    "\n",
    "def plot_cycle_counts(cycle_counts, skip_samples=[], palette=None):\n",
    "    '''\n",
    "        Create a stacked bar plot of nucleotide frequencies from a\n",
    "        set of FASTQ files of equal lengthed sequences.\n",
    "\n",
    "        Args:\n",
    "            cycle_counts:\n",
    "                        Dataframe of cycle counts as produced by the\n",
    "                        cycle_counts_from_fq function.\n",
    "\n",
    "            skip_samples:\n",
    "                        List of filenames to ignore.\n",
    "\n",
    "            palette:    Name of palette to use if the default colorscheme\n",
    "                        is not suitable for your purposes. Must available\n",
    "                        via seaborn's color_palette method (see\n",
    "                        https://seaborn.pydata.org/tutorial/color_palettes.html)\n",
    "\n",
    "    '''\n",
    "\n",
    "    if palette is None:\n",
    "        pal = nt_pal\n",
    "    else:\n",
    "        pal = sns.color_palette(palette, 5)\n",
    "    for fq in [\n",
    "            x for x in sorted(np.unique(cycle_counts.File))\n",
    "            if x not in skip_samples\n",
    "    ]:\n",
    "        plt.figure(figsize=(12, 9))\n",
    "        margin_bottom = np.zeros(len(cycle_counts.Cycle.drop_duplicates()))\n",
    "        for nt, i in nt2i.items():\n",
    "            color = pal[i]\n",
    "            tmp_df = cycle_counts[(cycle_counts.File == fq)\n",
    "                                  & (cycle_counts.Nucleotide == nt)]\n",
    "            plt.bar(tmp_df.Cycle.values,\n",
    "                    tmp_df.Count.values,\n",
    "                    color=color,\n",
    "                    edgecolor='white',\n",
    "                    width=1,\n",
    "                    label=nt,\n",
    "                    bottom=margin_bottom)\n",
    "            margin_bottom += tmp_df.Count.values\n",
    "        plt.xlabel(\"Cycle\")\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "        plt.title(\"Fastq {}\".format(fq))\n",
    "        ylim = plt.ylim()\n",
    "        new_ylim = [ylim[0], ylim[1] * 1.05]\n",
    "        plt.ylim(new_ylim)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_guide_coverage(bam, ref, minimum_aligned_length=0,\n",
    "                       minimum_fraction_aligned=0.0):\n",
    "    '''\n",
    "        Determine the number of reads aligned to sequences in FASTA reference\n",
    "        file in BAM alignment file. Returns a pandas dataframe of Target names\n",
    "        and read counts.\n",
    "\n",
    "        Args:\n",
    "            bam:    Alignment file in BAM/SAM format\n",
    "\n",
    "            ref:    FASTA reference file (same as used for creating BAM/SAM\n",
    "                    alignment)\n",
    "\n",
    "            minimum_aligned_length:\n",
    "                    Minimum number of bases that must have been aligned in\n",
    "                    order to count a record. Default=0\n",
    "\n",
    "            minimum_fraction_aligned:\n",
    "                    Minimum fraction of bases that must have been aligned in\n",
    "                    order to count a record. Default=0.0\n",
    "\n",
    "    '''\n",
    "    bamfile = pysam.AlignmentFile(bam)\n",
    "    fasta = pysam.FastaFile(ref)\n",
    "    total_reads = 0\n",
    "    unmapped = 0\n",
    "    counts = defaultdict(int)\n",
    "    mapping = {'mapped': [0], 'unmapped': [0], 'filtered': [0], 'passed': [0]}\n",
    "    for read in bamfile.fetch(until_eof=True):\n",
    "        total_reads += 1\n",
    "        if read.is_unmapped:\n",
    "            mapping['unmapped'][0] += 1\n",
    "        else:\n",
    "            mapping['mapped'][0] += 1\n",
    "            if minimum_aligned_length:\n",
    "                if read.query_alignment_length < minimum_aligned_length:\n",
    "                    mapping['filtered'][0] += 1\n",
    "                    continue\n",
    "            if minimum_fraction_aligned:\n",
    "                if (read.query_alignment_length/read.query_length <\n",
    "                        minimum_fraction_aligned):\n",
    "                    mapping['filtered'][0] += 1\n",
    "                    continue\n",
    "            counts[read.reference_name] += 1\n",
    "            mapping['passed'][0] += 1\n",
    "    print(\"{:,}/{:,} unmapped reads ({:g})\".format(\n",
    "        mapping['unmapped'][0], total_reads,\n",
    "        mapping['unmapped'][0]/total_reads))\n",
    "    count_rows = {'Target': [], 'Coverage': []}\n",
    "    for seq in fasta.references:\n",
    "        count_rows['Target'].append(seq)\n",
    "        if seq in counts:\n",
    "            count_rows['Coverage'].append(counts[seq])\n",
    "        else:\n",
    "            count_rows['Coverage'].append(0)\n",
    "    df = pd.DataFrame.from_dict(count_rows)\n",
    "    df.Target = df.Target.apply(lambda x: x.replace('~', '-'))\n",
    "    df['Gene'] = df.Target.apply(lambda x: target_from_ref(x)[0])\n",
    "    mapping_df = pd.DataFrame.from_dict(mapping)\n",
    "    return df, mapping_df\n",
    "\n",
    "def guide_coverage_from_bams(bam_dir, ref, extensions='.bam',\n",
    "                             skip_bams=[], minimum_aligned_length=0,\n",
    "                             minimum_fraction_aligned=0.0):\n",
    "    '''Returns dataframe of alignment counts for all BAMs in bam_dir.'''\n",
    "    bam2counts = pd.DataFrame()\n",
    "    bam2mapped = pd.DataFrame()\n",
    "    skip_bams = [os.path.join(bam_dir, x) for x in skip_bams]\n",
    "    for bam in (x for x in glob.glob('{}/*bam'.format(bam_dir)) if x not in\n",
    "                skip_bams):\n",
    "        print(\"Processing {}\".format(bam))\n",
    "        tmp_df, tmp_map_df = get_guide_coverage(bam, ref,\n",
    "                                                minimum_aligned_length,\n",
    "                                                minimum_fraction_aligned)\n",
    "        sample = os.path.basename(bam).rsplit(extensions, 1)[0]\n",
    "        tmp_df[\"Sample\"] = sample\n",
    "        tmp_map_df[\"Sample\"] = sample\n",
    "        bam2counts = pd.concat([bam2counts, tmp_df])\n",
    "        bam2mapped = pd.concat([bam2mapped, tmp_map_df])\n",
    "    return bam2counts,bam2mapped\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise the nucleotide content for all our guide sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ref_fasta in glob.glob(\"../../data/*.fa\"):\n",
    "    plot_fasta_nucleotide_counts(ref_fasta,\n",
    "                                 title = os.path.basename(ref_fasta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate our cycle counts for each of our fastq files in our fastq directory\n",
    "\n",
    "You can explore the dataframe generated as desired. We will plot nucleotide content per cycle.\n",
    "\n",
    "You may also want to use FASTQC to generate plots of other, more detailed metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# units_file = os.path.join(\"../../\", snakemake.config[\"units\"])\n",
    "# samples_file = os.path.join(\"../../\", snakemake.config[\"samples\"])\n",
    "units_file = \"../../config/units.tsv\"\n",
    "samples_file = \"../../config/samples.tsv\"\n",
    "fq_df = pd.read_csv(units_file, sep='\\t')\n",
    "unit2sample = dict(zip(fq_df.sample_name + \"-\" + fq_df.unit_name,\n",
    "                       fq_df.sample_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"../../results\", exist_ok=True)\n",
    "fq_counts = dict()\n",
    "for fq in fq_df.fq1:\n",
    "    fq_counts[fq] = cycle_counts_from_fq(fq,\n",
    "                                            progress_interval=5e6)\n",
    "print(\"Finished processing FASTQs. Creating dataframe.\")\n",
    "cycle_counts = defaultdict(list)\n",
    "for fq, counts in fq_counts.items():\n",
    "    fn = os.path.basename(fq).rstrip('.fastq.gz')\n",
    "    for i, row in enumerate(counts):\n",
    "        for j, n in enumerate(\"ACGTN\"):\n",
    "            cycle_counts[\"File\"].append(fn)\n",
    "            cycle_counts[\"Cycle\"].append(i + 1)\n",
    "            cycle_counts[\"Nucleotide\"].append(n)\n",
    "            cycle_counts[\"Count\"].append(row[j])\n",
    "cycle_counts = pd.DataFrame.from_dict(cycle_counts)\n",
    "cycle_counts.to_csv(\"../../results/cycle_counts.csv\", index=False)\n",
    "cycle_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cycle_counts(cycle_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Read Counts for each Guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bam2counts, bam2mapped = guide_coverage_from_bams(\"../../alignments/\", ref_fasta,\n",
    "                                                  extensions='.bam',\n",
    "                                                  minimum_aligned_length=15,\n",
    "                                                  minimum_fraction_aligned=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bam2counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = re.compile(r\"_S\\d+$\")\n",
    "bam2counts['Sample'] = bam2counts.Sample.map(unit2sample)\n",
    "bam2counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write to CSV, can regenerate dataframe using pd.read_csv('read_counts.csv')\n",
    "bam2counts.to_csv(\"../../results/read_counts.csv\", index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bam2mapped['Sample'] = bam2mapped.Sample.map(unit2sample)\n",
    "bam2mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write to CSV, can regenerate dataframe using pd.read_csv('mapping_counts.csv')\n",
    "bam2mapped.to_csv(\"../../results/mapping_counts.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot distribution of coverage of each guide for each sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.sort(np.unique(bam2counts.Sample.values)) \n",
    "#alternatively manually enter a list of sample IDs in your preferred order - e.g. samples = ['sample_1', 'sample_2']\n",
    "pal = sns.color_palette(\"colorblind\", len(samples))\n",
    "for i in range(len(samples)):\n",
    "    fig = plt.figure(figsize=(12,6))\n",
    "    sns.histplot(bam2counts[bam2counts.Sample == samples[i]].Coverage,\n",
    "                 kde=False, color=pal[i], label=samples[i])\n",
    "    plt.legend()\n",
    "    plt.ylabel('Guides')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of guides with at least one read mapped for first sample\n",
    "len(bam2counts[(bam2counts.Sample == samples[0]) &\n",
    "               (bam2counts.Coverage != 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of guides with no reads mapped for first sample\n",
    "len(bam2counts[(bam2counts.Sample == samples[0]) &\n",
    "               (bam2counts.Coverage == 0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate and plot distribution of fractions of total mapped reads for each guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp2mapped = dict()\n",
    "for lib in bam2mapped.Sample.unique():\n",
    "    samp2mapped[lib] = bam2mapped[bam2mapped.Sample == lib]['mapped'].values[0]\n",
    "    \n",
    "bam2counts[\"Fraction Reads Mapped\"] = bam2counts.apply(\n",
    "    lambda x: x.Coverage/samp2mapped[x.Sample],\n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(bam2counts, \n",
    "                  row=\"Sample\", hue=\"Sample\", palette=pal,\n",
    "                  row_order=samples, hue_order=samples,\n",
    "                  height=5,aspect=2, sharey=False)\n",
    "g = g.map(plt.hist, \"Fraction Reads Mapped\", bins=50, )\n",
    "for ax in g.axes.flatten():\n",
    "    ax.tick_params(labelbottom=True, labelleft=True)\n",
    "    ax.set_ylabel(\"Guides\")\n",
    "g.fig.tight_layout()\n",
    "plt.savefig(\"../../results/t0_guide_representation_hist.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create pivot table suitable for downstream analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bam2counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bam2counts_pivot = bam2counts.pivot_table(index=\"Target\", columns=\"Sample\")['Coverage'].reset_index()\n",
    "bam2counts_pivot.columns.name = None\n",
    "bam2counts_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bam2counts_pivot['Gene'] = bam2counts_pivot.Target.apply(lambda x: target_from_ref(x)[0])\n",
    "bam2counts_pivot.to_csv(\"../../results/read_counts_pivot.txt\", sep='\\t', index=False)\n",
    "bam2counts_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bam2frac_pivot = bam2counts.pivot_table(index=\"Target\",\n",
    "                                        columns=\"Sample\")['Fraction Reads Mapped'].reset_index()\n",
    "bam2frac_pivot.columns.name = None\n",
    "bam2frac_pivot.head()\n",
    "bam2frac_pivot['Gene'] = bam2frac_pivot.Target.apply(lambda x: target_from_ref(x)[0])\n",
    "bam2frac_pivot.to_csv(\"../../results/fraction_counts_pivot.txt\", sep='\\t', index=False)\n",
    "bam2frac_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
